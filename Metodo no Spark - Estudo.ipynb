{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import wrap\n",
    "def convert_int(x):\n",
    "    return int(x,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_data = sc.textFile('../data-fingerprint/2002_DB1a_data/Vector_Index/1_1.tif.bmp.wsq.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00000011',\n",
       " '11110000',\n",
       " '00000011',\n",
       " '11111111',\n",
       " '00000001',\n",
       " '11111111',\n",
       " '11100000',\n",
       " '11111111',\n",
       " '11111100',\n",
       " '01111111',\n",
       " '11111111',\n",
       " '10011111',\n",
       " '11111111',\n",
       " '11101111',\n",
       " '11111111',\n",
       " '11111111',\n",
       " '11111111',\n",
       " '11111111',\n",
       " '11111111',\n",
       " '11111111',\n",
       " '11111111',\n",
       " '11111111',\n",
       " '11111111',\n",
       " '11111111',\n",
       " '11111111',\n",
       " '11111111',\n",
       " '11111111',\n",
       " '01111111',\n",
       " '11111111',\n",
       " '10011111',\n",
       " '11111111',\n",
       " '11100011',\n",
       " '11111111',\n",
       " '11110000',\n",
       " '01111111',\n",
       " '11111000',\n",
       " '00001111',\n",
       " '11111100',\n",
       " '00000000',\n",
       " '11111100',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00010000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00001100',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '01100011',\n",
       " '00001000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00011000',\n",
       " '11000010',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000110',\n",
       " '00110000',\n",
       " '10000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000001',\n",
       " '10001100',\n",
       " '00100000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00100001',\n",
       " '00001000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00010000',\n",
       " '10000100',\n",
       " '00100000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000100',\n",
       " '01110011',\n",
       " '10001000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000001',\n",
       " '00011100',\n",
       " '11100010',\n",
       " '00000000',\n",
       " '00010001',\n",
       " '10001000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000010',\n",
       " '00010000',\n",
       " '00000000',\n",
       " '10000100',\n",
       " '01000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '00000000',\n",
       " '0000000']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_data.map(lambda x:x.replace(\" \",\"\")).map(lambda x:wrap(x,8)).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 240,\n",
       " 3,\n",
       " 255,\n",
       " 1,\n",
       " 255,\n",
       " 224,\n",
       " 255,\n",
       " 252,\n",
       " 127,\n",
       " 255,\n",
       " 159,\n",
       " 255,\n",
       " 239,\n",
       " 255,\n",
       " 255,\n",
       " 255,\n",
       " 255,\n",
       " 255,\n",
       " 255,\n",
       " 255,\n",
       " 255,\n",
       " 255,\n",
       " 255,\n",
       " 255,\n",
       " 255,\n",
       " 255,\n",
       " 127,\n",
       " 255,\n",
       " 159,\n",
       " 255,\n",
       " 227,\n",
       " 255,\n",
       " 240,\n",
       " 127,\n",
       " 248,\n",
       " 15,\n",
       " 252,\n",
       " 0,\n",
       " 252,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 16,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 12,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 99,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 24,\n",
       " 194,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 48,\n",
       " 128,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 140,\n",
       " 32,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 33,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 16,\n",
       " 132,\n",
       " 32,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 115,\n",
       " 136,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 28,\n",
       " 226,\n",
       " 0,\n",
       " 17,\n",
       " 136,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 16,\n",
       " 0,\n",
       " 132,\n",
       " 64,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_data.map(lambda x:x.replace(\" \",\"\")).map(lambda x:wrap(x,8)).map(lambda x: list(map(lambda x1: int(x1,2),x))).first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepocessing( Create Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashs = sc.parallelize(list(range(192)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating 'Hash1 ' index...\n"
     ]
    }
   ],
   "source": [
    "def create_index(pos):\n",
    "    from elasticsearch import Elasticsearch\n",
    "    es = Elasticsearch()\n",
    "    request_body = {\n",
    "        \"settings\" : {\n",
    "            \"number_of_shards\": 5,\n",
    "            \"number_of_replicas\": 1\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"pos\": {\n",
    "                \"properties\": {\n",
    "                    \"text\": {\"type\":\"text\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    es.indices.create(index = 'hash{}'.format(pos), body = request_body,request_timeout=10000)\n",
    "    return 1\n",
    "\n",
    "\n",
    "hashs.map(lambda x:create_index(x)).collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserir no Índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(68, [])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import helpers\n",
    "def gendata(list_pos_in_hash, id):\n",
    "    for i,pos in enumerate(list_pos_in_hash):\n",
    "        if(pos != 0):\n",
    "            yield {\n",
    "                    \"_index\": \"hash{}\".format(i),\n",
    "                    \"_type\": \"pos\",\n",
    "                    \"_id\": str(pos),\n",
    "                    \"_source\": {\n",
    "                    \"text\": \"P{}_M0\".format(id)\n",
    "                   }\n",
    "\n",
    "            } \n",
    "list_pos_min_1 = vector_data.map(lambda x:x.replace(\" \",\"\")).map(lambda x:wrap(x,8)).map(lambda x: list(map(lambda x1: int(x1,2),x))).first()\n",
    "#list(gendata(list_pos_min_1,1))\n",
    "helpers.bulk(es, gendata(list_pos_min_1,1),request_timeout=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiSearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pos_min_1 = [vector_data.map(lambda x:x.replace(\" \",\"\")).map(lambda x:wrap(x,8)).map(lambda x: list(map(lambda x1: int(x1,2),x))).first()]\n",
    "min_1 = sc.parallelize(list_pos_min_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gendata1(list_pos_in_hash):\n",
    "    for i,pos in enumerate(list_pos_in_hash):\n",
    "        if(pos != 0):\n",
    "            yield {\"index\": \"hash{}\".format(i) }\n",
    "            yield {\n",
    "                    \"query\": {\"terms\": {\"_id\":[str(pos)]}}} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def realize_search(data_consult):\n",
    "    from elasticsearch import Elasticsearch\n",
    "    es = Elasticsearch()\n",
    "    data_response = es.msearch(body=data_consult)\n",
    "    return list(map(lambda x : x['hits']['hits'][0]['_source']['text'], data_response['responses']))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0',\n",
       "  'P1_M0']]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_ = min_1.map(lambda x : list(gendata1(x))).map(lambda x: realize_search(x)).collect()\n",
    "list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_ = [[\"P2_M1 P1_M4 \",\"P2_M1 P3_M2 P3_M2 P1_M4\",\"P2_M1 P2_M3 P1_M4\",\"P2_M1 P4_M1 P1_M4\"],[\"P2_M4 P1_M4\",\"P2_M1 P3_M2 P3_M2\",\"P2_M1 P2_M3\",\"P2_M1 P4_M1 P1_M1\"]]\n",
    "\n",
    "words_list = sc.parallelize(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def func_count_byKey_return_max(x):\n",
    "    x_,y_ = np.unique(x,return_counts=True)\n",
    "    y_max = np.max(y_)\n",
    "    return \" \".join([ i[0].split('_')[0] for i in list(filter(lambda x: x[1] == y_max,list(map(lambda x,y:(x,y) ,x_,y_)))) ])\n",
    "\n",
    "def func_rank_elements(persons):\n",
    "    persons_list, count_ = np.unique(persons.split(\" \"),return_counts=True)\n",
    "    return persons_list[np.argsort(-1*count_)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
      "Wall time: 13.6 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['P1'], dtype='<U2')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "persons = words_list.map(lambda x : \" \".join(x)).map(lambda x : x.split()).map(func_count_byKey_return_max ).reduce(lambda x,y: y + \" \"+ x)\n",
    "func_rank_elements(persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testes no ElasticSearch com elementos no mesmo indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch,helpers\n",
    "def create_index():\n",
    "    es = Elasticsearch()\n",
    "    request_body = {\n",
    "        \"settings\" : {\n",
    "            \"number_of_shards\": 5,\n",
    "            \"number_of_replicas\": 1\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"hash\": {\n",
    "                \"properties\": {\n",
    "                    \"value\": {\"type\":\"text\"},\n",
    "                    \"index_in_hash\":{\n",
    "                        \"type\": \"nested\",\n",
    "                        \"properties\":{\n",
    "                            \"text\":{\"type\": \"text\"},\n",
    "                            \"id\": {\"type\": \"text\"}\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    es.indices.create(index = 'hashs', body = request_body,request_timeout=10000)\n",
    "    return 1\n",
    "\n",
    "\n",
    "create_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 65.3 ms, sys: 0 ns, total: 65.3 ms\n",
      "Wall time: 427 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(192, [])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "from elasticsearch import Elasticsearch,helpers\n",
    "es = Elasticsearch()\n",
    "\n",
    "def init_hashs(num_hash,num_bits):\n",
    "    \n",
    "    text = list(map(lambda x: {\"text\":\"\", \"id\":str(x)},list(range(2**num_bits))))\n",
    "\n",
    "    for pos in range(num_hash):\n",
    "\n",
    "        yield { \"_op_type\":\"create\",\n",
    "                \"_index\": \"hashs\",\n",
    "                \"_type\": \"hash\",\n",
    "                \"_id\": str(pos),\n",
    "                \"_source\": {\n",
    "                    \"value\":str(pos),\n",
    "                    \"index_in_hash\":text\n",
    "\n",
    "               }\n",
    "\n",
    "        } \n",
    "#list(gendata(list_pos_min_1,1))\n",
    "helpers.bulk(es, init_hashs(192,8),request_timeout=1000)\n",
    "#a = list(init_hashs(192,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.6 ms, sys: 4.07 ms, total: 21.7 ms\n",
      "Wall time: 487 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(191, [])"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "from elasticsearch import Elasticsearch,helpers\n",
    "es = Elasticsearch()\n",
    "\n",
    "def att_hashs(num_hash):\n",
    "    \n",
    "    #text = list(map(lambda x: {\"text\":\"\", \"id\":str(x)},list(range(2**num_bits))))\n",
    "    \n",
    "    for i,pos in enumerate(range(num_hash)):\n",
    "        if(pos != 0):\n",
    "            yield { \"_op_type\":\"update\",\n",
    "                    \"_index\": \"hashs\",\n",
    "                    \"_type\": \"hash\",\n",
    "                    \"_id\": str(pos),\n",
    "                    \"_source\": {\n",
    "                        \"script\": {\n",
    "                            \"source\": \" def targets = ctx._source.index_in_hash.findAll(hash_ele -> hash_ele.id == params.hash_index); for(hash_ele in targets){hash_ele.text = hash_ele.text + params.new_text}\",\n",
    "#                            \"source\": \"ctx._source.hash[params.position].text = ctx._source.hash[params.position].text +params.new_text;\",\n",
    "                            \"params\":{\n",
    "                                \"hash_index\":\"255\",\n",
    "                                \"new_text\":\"AAAAVVVVAA \"\n",
    "                            }\n",
    "                            \n",
    "                            \n",
    "                      #  \"value\":str(pos),\n",
    "                       # \"index_in_hash\":text\n",
    "                        }\n",
    "                   }\n",
    "\n",
    "            } \n",
    "#list(gendata(list_pos_min_1,1))\n",
    "helpers.bulk(es, att_hashs(192),request_timeout=1000)\n",
    "#list(init_hashs(192,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gendata1(list_pos_in_hash):\n",
    "    for i,pos in enumerate(list_pos_in_hash):\n",
    "        if(pos != 0):\n",
    "            yield {\"index\": \"hashs\" }\n",
    "            yield {\n",
    "                    \"query\": {\n",
    "                        \"nested\":{\n",
    "                            \"path\": \"index_in_hash\",\n",
    "                            \"query\":{\n",
    "                                \"bool\": {\n",
    "                                    \"must\": [\n",
    "                                        {\"match\": {\"index_in_hash.id\":str(pos)}},\n",
    "                                        {\"match\": {\"index_in_hash.value\":str(i)}}\n",
    "\n",
    "                                     #   {\"match\":{\n",
    "                                      #      \"hash.value\": str(i)}},\n",
    "                                      #  {\"match\":{\n",
    "                                      #      \"hash.index_in_hash.id\": str(pos)}}\n",
    "                                    ]\n",
    "                                }\n",
    "                            },\n",
    "                            \"inner_hits\":{\n",
    "                                \"highlight\":{\n",
    "                                    \"fields\":{\n",
    "                                        \"index_in_hash\": {}\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "            } \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gendata1(list_pos_in_hash):\n",
    "    for i,pos in enumerate(list_pos_in_hash):\n",
    "        if(pos != 0):\n",
    "            yield {\"index\": \"hashs\" }\n",
    "            yield {\n",
    "                    \"_source\":\"false\",\n",
    "\n",
    "                    \"query\": {\n",
    "                        \"bool\":{\n",
    "                            \"filter\":{\n",
    "                                \"bool\":{\n",
    "                                \"must\":[\n",
    "                                \n",
    "                                {\"match\":{\"_id\":str(i)}},\n",
    "                                    \n",
    "                                    \n",
    "                                {\"nested\":{\n",
    "                                    \"path\": \"index_in_hash\",\n",
    "                                    \"query\":{\n",
    "                                        \"match\": {\"index_in_hash.id\":str(pos)}},\n",
    "                                    \"inner_hits\":{}\n",
    "                                }}\n",
    "                                ]\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "            }\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gendata1(list_pos_in_hash):\n",
    "    for i,pos in enumerate(list_pos_in_hash):\n",
    "        if(pos != 0):\n",
    "            yield {\"index\": \"hashs\" }\n",
    "            yield {\n",
    "                    \"_source\":\"false\",\n",
    "                    \"query\": {\n",
    "                        \"nested\":{\n",
    "                            \"path\": \"index_in_hash\",\n",
    "                            \"query\":{\n",
    "                                \"bool\": {\n",
    "                                    \"must\": [\n",
    "                                        {\"match\": {\"index_in_hash.id\":str(pos)}},\n",
    "                                        {\"match\": {\"index_in_hash.value\":str(i)}}\n",
    "\n",
    "                                     #   {\"match\":{\n",
    "                                      #      \"hash.value\": str(i)}},\n",
    "                                      #  {\"match\":{\n",
    "                                      #      \"hash.index_in_hash.id\": str(pos)}}\n",
    "                                    ]\n",
    "                                }\n",
    "                            },\n",
    "                            \"inner_hits\":{\n",
    "                              \n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "            } \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def realize_search(data_consult):\n",
    "    from elasticsearch import Elasticsearch\n",
    "    es = Elasticsearch()\n",
    "    data_response = es.msearch(body=data_consult)\n",
    "    return list(map(lambda x : x['hits']['hits'][0]['inner_hits']['index_in_hash']['hits']['hits'][0]['_source']['text'], data_response['responses']))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'AAAAVVVVAA ', '', 'AAAAVVVVAA ']"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "realize_search(list(gendata1([255,255,10,255])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
