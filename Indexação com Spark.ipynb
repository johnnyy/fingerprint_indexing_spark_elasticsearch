{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system(\"./../source/generate_vector_python ~/Projeto/TCC/data-fingerprint/2002_DB1a_data/finger_index.txt  ../data-fingerprint/2002_DB1a_data/Vector_Index/ {} {} {}\".format(16,5,0))\n",
    "os.system(\"./../source/generate_vector_python ~/Projeto/TCC/data-fingerprint/2002_DB1a_data/finger_search.txt  ../data-fingerprint/2002_DB1a_data/Vector_Search/ {} {} {}\".format(16,5,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do índice ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch,helpers\n",
    "def create_index():\n",
    "    es = Elasticsearch()\n",
    "    request_body = {\n",
    "        \"settings\" : {\n",
    "            \"number_of_shards\": 5,\n",
    "            \"number_of_replicas\": 1\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"hash\": {\n",
    "                \"properties\": {\n",
    "                    \"value\": {\"type\":\"text\"},\n",
    "                    \"index_in_hash\":{\n",
    "                        \"type\": \"nested\",\n",
    "                        \"properties\":{\n",
    "                            \"text\":{\"type\": \"text\"},\n",
    "                            \"id\": {\"type\": \"text\"}\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    es.indices.create(index = 'hashs', body = request_body,request_timeout=10000)\n",
    "    return 1\n",
    "\n",
    "\n",
    "create_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializando os elementos no índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.2 ms, sys: 203 µs, total: 40.4 ms\n",
      "Wall time: 301 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(192, [])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "from elasticsearch import Elasticsearch,helpers\n",
    "es = Elasticsearch()\n",
    "\n",
    "def init_hashs(num_hash,num_bits):\n",
    "    \n",
    "    text = list(map(lambda x: {\"text\":\"\", \"id\":str(x)},list(range(2**num_bits))))\n",
    "\n",
    "    for pos in range(num_hash):\n",
    "\n",
    "        yield { \"_op_type\":\"create\",\n",
    "                \"_index\": \"hashs\",\n",
    "                \"_type\": \"hash\",\n",
    "                \"_id\": str(pos),\n",
    "                \"_source\": {\n",
    "                    \"value\":str(pos),\n",
    "                    \"index_in_hash\":text\n",
    "\n",
    "               }\n",
    "\n",
    "        } \n",
    "#list(gendata(list_pos_min_1,1))\n",
    "helpers.bulk(es, init_hashs(192,8),request_timeout=1000)\n",
    "#a = list(init_hashs(192,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função para gerar text para bulk para indexar ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch,helpers\n",
    "es = Elasticsearch()\n",
    "\n",
    "def att_hashs(list_positions,id_,id_min):   \n",
    "    for i,pos in enumerate(list_positions):\n",
    "        if(pos != 0):\n",
    "            yield { \"_op_type\":\"update\",\n",
    "                    \"_index\": \"hashs\",\n",
    "                    \"_type\": \"hash\",\n",
    "                    \"_id\": str(i),\n",
    "                    \"_source\": {\n",
    "                        \"script\": {\n",
    "                            \"source\": \" def targets = ctx._source.index_in_hash.findAll(hash_ele -> hash_ele.id == params.hash_index); for(hash_ele in targets){hash_ele.text = hash_ele.text + params.new_text}\",\n",
    "                            \"params\":{\n",
    "                                \"hash_index\":str(pos),\n",
    "                                \"new_text\":\"P{}_M{} \".format(id_,id_min)\n",
    "                            }\n",
    "                        }\n",
    "                   }\n",
    "            } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 26_4.tif.bmp.wsq.txt\n",
      "2 63_6.tif.bmp.wsq.txt\n",
      "3 64_1.tif.bmp.wsq.txt\n",
      "4 12_6.tif.bmp.wsq.txt\n",
      "5 4_6.tif.bmp.wsq.txt\n",
      "6 92_6.tif.bmp.wsq.txt\n",
      "7 53_3.tif.bmp.wsq.txt\n",
      "8 40_6.tif.bmp.wsq.txt\n",
      "9 9_2.tif.bmp.wsq.txt\n",
      "10 49_4.tif.bmp.wsq.txt\n",
      "CPU times: user 3.32 s, sys: 49.8 ms, total: 3.37 s\n",
      "Wall time: 51.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "from textwrap import wrap\n",
    "import os\n",
    "for x,i,files in os.walk(\"../data-fingerprint/2002_DB1a_data/Vector_Index/\"):\n",
    "    for ind,file in enumerate(files):\n",
    "        if(ind ==10):\n",
    "            break\n",
    "        print(ind+1,file)\n",
    "        vector_data = sc.textFile(x + file)\n",
    "        list_positions = vector_data.map(lambda x:x.replace(\" \",\"\")).map(lambda x:wrap(x,8)).map(lambda x: list(map(lambda x1: int(x1,2),x)) ).collect()\n",
    "        id = int(file.split('_')[0])\n",
    "        len_list = len(list_positions)\n",
    "        es = Elasticsearch()\n",
    "        #list(map( lambda x : helpers.bulk(es,x,request_timeout=1000) , list(map( att_hashs, list_positions, np.repeat(id,len_list), list(range(len_list)) ) ) ) )\n",
    "        list_for_bulk = list(map( lambda x : list(x) , list(map( att_hashs, list_positions, np.repeat(id,len_list), list(range(len_list)) ) ) ) )\n",
    "        list_for_bulk = [item for sublist in list_for_bulk for item in sublist]\n",
    "        helpers.bulk(es,list_for_bulk,request_timeout=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexação com função para agrupar conjunto de texto em memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch,helpers\n",
    "es = Elasticsearch()\n",
    "\n",
    "def att_hashs(hash_id,i):\n",
    "    \n",
    "    for pos,text in enumerate(hash_id):\n",
    "        if(text != ''):\n",
    "            yield { \"_op_type\":\"update\",\n",
    "                    \"_index\": \"hashs\",\n",
    "                    \"_type\": \"hash\",\n",
    "                    \"_id\": str(i),\n",
    "                    \"_source\": {\n",
    "                        \"script\": {\n",
    "                            \"source\": \" def targets = ctx._source.index_in_hash.findAll(hash_ele -> hash_ele.id == params.hash_index); for(hash_ele in targets){hash_ele.text = hash_ele.text + params.new_text}\",\n",
    "                            \"params\":{\n",
    "                                \"hash_index\":str(pos),\n",
    "                                \"new_text\":text\n",
    "                            }\n",
    "                        }\n",
    "                   }\n",
    "            } \n",
    "\n",
    "def convert_hash_to_bulk(hash):\n",
    "    return [item for sublist in list(map(lambda x,i:att_hashs(x,i),hash.text_in_hashs,list(range(len(hash.text_in_hashs))))) for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_value_in_hash(string_text,index,position):\n",
    "    global hashs\n",
    "    \n",
    "    hashs.text_in_hashs[index][position]+=string_text\n",
    "    \n",
    "def generate_word(list_index,id,id_min):\n",
    "    #id = 1\n",
    "    return list(map(lambda pos_hash,index_hash: set_value_in_hash(\"P{}_M{} \".format(id,id_min),index_hash,pos_hash) if(pos_hash > 0) else None ,list_index,list(range(len(list_index)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 26_4.tif.bmp.wsq.txt\n",
      "2 63_6.tif.bmp.wsq.txt\n",
      "3 64_1.tif.bmp.wsq.txt\n",
      "4 12_6.tif.bmp.wsq.txt\n",
      "5 4_6.tif.bmp.wsq.txt\n",
      "6 92_6.tif.bmp.wsq.txt\n",
      "7 53_3.tif.bmp.wsq.txt\n",
      "8 40_6.tif.bmp.wsq.txt\n",
      "9 9_2.tif.bmp.wsq.txt\n",
      "10 49_4.tif.bmp.wsq.txt\n",
      "CPU times: user 675 ms, sys: 20.2 ms, total: 695 ms\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np\n",
    "from textwrap import wrap\n",
    "import os\n",
    "es = Elasticsearch()\n",
    "\n",
    "for x,i,files in os.walk(\"../data-fingerprint/2002_DB1a_data/Vector_Index/\"):\n",
    "    hashs = Hash(192,8)\n",
    "    for ind,file in enumerate(files):\n",
    "        if(ind %10 == 0 and ind != 0):\n",
    "            \n",
    "            list_for_bulk = convert_hash_to_bulk(hashs)\n",
    "            helpers.bulk(es,list_for_bulk,request_timeout=1000)\n",
    "            break\n",
    "            hashs = Hash(192,8)\n",
    "\n",
    "            \n",
    "        print(ind+1,file)\n",
    "        vector_data = sc.textFile(x + file)\n",
    "        list_positions = vector_data.map(lambda x:x.replace(\" \",\"\")).map(lambda x:wrap(x,8)).map(lambda x: list(map(lambda x1: int(x1,2),x)) ).collect()\n",
    "        id = int(file.split('_')[0])\n",
    "        len_list = len(list_positions)\n",
    "        list(map(generate_word, list_positions, np.repeat(id,len_list), list(range(len_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hash:\n",
    "    def __init__(self, num_hashs, num_bits):\n",
    "        self.text_in_hashs = []\n",
    "        self.num_bits = num_bits\n",
    "        self.num_hashs = num_hashs\n",
    "        self.size_bucket = 2**num_bits\n",
    "        self.text_in_hashs = list(map(lambda x:list(map(lambda x1: \"\",list(range(self.size_bucket)))),list(range(self.num_hashs))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final do metódo de indexação com conjunto de texto em memória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from textwrap import wrap\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gendata1(list_pos_in_hash):\n",
    "    list_not_index = [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
    "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
    "        26,  27,  28,  29,  30,  31,  43,  50, 173, 180, 32,  33,  34,  39,  40,  41,  42,  51,  52,  61, 162, 171, 172,\n",
    "       181, 182, 183, 184, 189, 190, 191]\n",
    "  #  list_not_index= []\n",
    "    for i,pos in enumerate(list_pos_in_hash):\n",
    "        if(pos != 0 and i not in list_not_index):\n",
    "            yield {\"index\": \"hashs\" }\n",
    "            yield {\n",
    "                    \"_source\":\"false\",\n",
    "\n",
    "                    \"query\": {\n",
    "                        \"bool\":{\n",
    "                            \"filter\":{\n",
    "                                \"bool\":{\n",
    "                                \"must\":[\n",
    "                                \n",
    "                                {\"match\":{\"_id\":str(i)}},\n",
    "                                    \n",
    "                                    \n",
    "                                {\"nested\":{\n",
    "                                    \"path\": \"index_in_hash\",\n",
    "                                    \"query\":{\n",
    "                                        \"match\": {\"index_in_hash.id\":str(pos)}},\n",
    "                                    \"inner_hits\":{}\n",
    "                                }}\n",
    "                                ]\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "            }\n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "                            \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def realize_search(data_consult):\n",
    "    from elasticsearch import Elasticsearch\n",
    "    es = Elasticsearch()\n",
    "    if(data_consult != []):\n",
    "        data_response = es.msearch(body=data_consult)\n",
    "        return list(map(lambda x : x['hits']['hits'][0]['inner_hits']['index_in_hash']['hits']['hits'][0]['_source']['text'], data_response['responses']))\n",
    "    else:\n",
    "        return []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def func_count_byKey_return_max(x):\n",
    "    if(x != []):\n",
    "        import numpy as np\n",
    "        x_,y_ = np.unique(x,return_counts=True)\n",
    "        y_max = np.max(y_)\n",
    "        return \" \".join([ i[0].split('_')[0] for i in list(filter(lambda x: x[1] == y_max,list(map(lambda x,y:(x,y) ,x_,y_)))) ])\n",
    "    else:\n",
    "        return \"\"\n",
    "def func_rank_elements(persons):\n",
    "    persons_list, count_ = np.unique(persons.split(\" \"),return_counts=True)\n",
    "    return persons_list[np.argsort(-1*count_)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "CPU times: user 14.5 ms, sys: 131 µs, total: 14.6 ms\n",
      "Wall time: 387 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vector_data = sc.textFile('../data-fingerprint/2002_DB1a_data/Vector_Search/49_1.tif.bmp.wsq.txt')\n",
    "persons = vector_data.map(lambda x:x.replace(\" \",\"\")).map(lambda x:wrap(x,8)).map(lambda x: list(map(lambda x1: int(x1,2),x))).map(lambda x : list(gendata1(x))).map(lambda x: realize_search(x)).map(lambda x : \" \".join(x)).map(lambda x : x.split()).map(func_count_byKey_return_max ).reduce(lambda x,y: y + \" \"+ x).replace(\"  \", \" \")\n",
    "ranking = func_rank_elements(persons)\n",
    "pos_  = -1\n",
    "id = \"49\"\n",
    "\n",
    "for p in range(len(ranking)):\n",
    "    if(id  == ranking[p].split('P')[1]):\n",
    "        pos_ = p + 1\n",
    "        break\n",
    "print(pos_)\n",
    "#pos_rank[i].append([pos_,file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 1 filename: 1_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 2 filename: 91_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 3 filename: 87_4.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 4 filename: 11_7.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 5 filename: 58_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 6 filename: 38_3.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 7 filename: 15_8.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 8 filename: 10_2.tif.bmp.wsq.txt pos_rank: 2\n",
      "count: 9 filename: 98_2.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 10 filename: 74_4.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 11 filename: 87_1.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 12 filename: 88_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 13 filename: 60_1.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 14 filename: 4_8.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 15 filename: 73_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 16 filename: 67_1.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 17 filename: 57_3.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 18 filename: 54_2.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 19 filename: 81_5.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 20 filename: 82_1.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 21 filename: 28_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 22 filename: 18_3.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 23 filename: 36_5.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 24 filename: 21_1.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 25 filename: 21_8.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 26 filename: 96_3.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 27 filename: 87_7.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 28 filename: 14_7.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 29 filename: 31_5.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 30 filename: 77_2.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 31 filename: 72_3.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 32 filename: 46_1.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 33 filename: 80_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 34 filename: 74_7.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 35 filename: 35_2.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 36 filename: 83_7.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 37 filename: 27_2.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 38 filename: 67_2.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 39 filename: 19_8.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 40 filename: 6_4.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 41 filename: 64_5.tif.bmp.wsq.txt pos_rank: 2\n",
      "count: 42 filename: 3_5.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 43 filename: 95_3.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 44 filename: 65_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 45 filename: 92_5.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 46 filename: 47_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 47 filename: 82_7.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 48 filename: 16_2.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 49 filename: 6_1.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 50 filename: 20_3.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 51 filename: 59_7.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 52 filename: 23_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 53 filename: 52_3.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 54 filename: 22_2.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 55 filename: 37_5.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 56 filename: 54_5.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 57 filename: 27_1.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 58 filename: 80_1.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 59 filename: 92_3.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 60 filename: 86_7.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 61 filename: 67_8.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 62 filename: 43_4.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 63 filename: 94_8.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 64 filename: 56_8.tif.bmp.wsq.txt pos_rank: 3\n",
      "count: 65 filename: 40_4.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 66 filename: 38_8.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 67 filename: 60_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 68 filename: 59_3.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 69 filename: 59_4.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 70 filename: 11_8.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 71 filename: 12_2.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 72 filename: 24_8.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 73 filename: 39_4.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 74 filename: 9_1.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 75 filename: 52_8.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 76 filename: 47_1.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 77 filename: 17_3.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 78 filename: 27_4.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 79 filename: 92_4.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 80 filename: 74_5.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 81 filename: 23_2.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 82 filename: 59_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 83 filename: 77_5.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 84 filename: 50_2.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 85 filename: 19_4.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 86 filename: 96_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 87 filename: 98_3.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 88 filename: 42_8.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 89 filename: 24_3.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 90 filename: 32_8.tif.bmp.wsq.txt pos_rank: 3\n",
      "count: 91 filename: 75_1.tif.bmp.wsq.txt pos_rank: 12\n",
      "count: 92 filename: 96_2.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 93 filename: 57_4.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 94 filename: 90_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 95 filename: 16_3.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 96 filename: 13_4.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 97 filename: 79_4.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 98 filename: 81_7.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 99 filename: 79_7.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 100 filename: 98_4.tif.bmp.wsq.txt pos_rank: 3\n",
      "count: 101 filename: 85_1.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 102 filename: 45_5.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 103 filename: 15_4.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 104 filename: 9_3.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 105 filename: 62_8.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 106 filename: 25_7.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 107 filename: 61_4.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 108 filename: 26_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 109 filename: 54_3.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 110 filename: 95_7.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 111 filename: 92_8.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 112 filename: 99_5.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 113 filename: 97_7.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 114 filename: 45_1.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 115 filename: 98_8.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 116 filename: 98_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 117 filename: 88_8.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 118 filename: 29_4.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 119 filename: 84_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 120 filename: 66_7.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 121 filename: 44_1.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 122 filename: 9_5.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 123 filename: 97_8.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 124 filename: 70_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 125 filename: 40_1.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 126 filename: 31_1.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 127 filename: 57_5.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 128 filename: 85_7.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 129 filename: 18_7.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 130 filename: 17_1.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 131 filename: 16_5.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 132 filename: 62_6.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 133 filename: 1_8.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 134 filename: 32_7.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 135 filename: 1_3.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 136 filename: 60_5.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 137 filename: 50_5.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 138 filename: 27_5.tif.bmp.wsq.txt pos_rank: 1\n",
      "count: 139 filename: 80_5.tif.bmp.wsq.txt pos_rank: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-814669a9bc6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m        \u001b[0;31m# print(file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mvector_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mpersons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgendata1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrealize_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_count_byKey_return_max\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mranking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_rank_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpersons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/Spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/Spark/python/pyspark/rdd.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \"\"\"\n\u001b[1;32m    888\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectAndServe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/Spark/python/lib/py4j-0.10.8.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1286\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/opt/Spark/python/lib/py4j-0.10.8.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/Spark/python/lib/py4j-0.10.8.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pos_rank =[]\n",
    "for x,i,files in os.walk(\"../data-fingerprint/2002_DB1a_data/Vector_Search/\"):\n",
    "    count = 0\n",
    "    for file in files:\n",
    "        \n",
    "       # print(file)\n",
    "        vector_data = sc.textFile(x + file)\n",
    "        persons = vector_data.map(lambda x:x.replace(\" \",\"\")).map(lambda x:wrap(x,8)).map(lambda x: list(map(lambda x1: int(x1,2),x))).map(lambda x : list(gendata1(x))).map(lambda x: realize_search(x)).map(lambda x : \" \".join(x)).map(lambda x : x.split()).map(func_count_byKey_return_max ).reduce(lambda x,y: y + \" \"+ x).replace(\"  \", \" \")\n",
    "        ranking = func_rank_elements(persons)\n",
    "        id = file.split(\"_\")[0]\n",
    "        pos_  = -1\n",
    "        for p in range(len(ranking)):\n",
    "            if(id  == ranking[p].split('P')[1]):\n",
    "                pos_ = p + 1\n",
    "                break\n",
    "        count+=1\n",
    "        print(\"count:\",count,\"filename:\",file,\"pos_rank:\",pos_)\n",
    "        pos_rank.append([pos_,file])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pos_rank,columns=['pos_rank','file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 2)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(680, 2)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['pos_rank'] >0) & (df['pos_rank'] <10)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 2)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisando  o índice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johnny/.local/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.25.8) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import  pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch()\n",
    "count_index_voids = []\n",
    "for i in range(192):\n",
    "    data_r = es.get(index=\"hashs\",id=i,doc_type=\"hash\")\n",
    "    count_void_elements = 0\n",
    "    for partial_data in data_r['_source']['index_in_hash']:\n",
    "        if(partial_data['text'] == ''):\n",
    "            count_void_elements +=1\n",
    " #   if(count_void_elements len(data_r['_source']['index_in_hash']))\n",
    "    count_index_voids.append([count_void_elements,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(count_index_voids,columns=['voids','index'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Existem 20 hashs em que todos os elementos caíram em 0 e foram eliminados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['voids'] >255].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 32,  33,  34,  39,  40,  41,  42,  51,  52,  61, 162, 171, 172,\n",
       "       181, 182, 183, 184, 189, 190, 191])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['voids'] >255]['index'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Existem 36 hashs que todos os elementos estão na mesma posição, ou seja, são dados agrupados na mesma posição (muito volume) e são irrelevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['voids'] ==255].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  43,  50, 173, 180])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['voids'] ==255]['index'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
